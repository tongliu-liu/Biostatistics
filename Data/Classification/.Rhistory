A_pos_frq <- data.frame(A_pos_frq)
T_pos_frq <- data.frame(T_pos_frq)
C_pos_frq <- data.frame(C_pos_frq)
G_pos_frq <- data.frame(G_pos_frq)
neg_frq <- cbind(A_neg_frq,T_neg_frq,C_neg_frq,G_neg_frq)
pos_frq <- cbind(A_pos_frq,T_pos_frq,C_pos_frq,G_pos_frq)
category <- c(rep("neg",nrow(neg_frq)))
neg_frq <- cbind(neg_frq,category)
category <- c(rep("pos",nrow(pos_frq)))
pos_frq <- cbind(pos_frq,category)
head(neg_frq)
head(pos_frq)
data_frq <- rbind(neg_frq,pos_frq)
data_frq[is.na(data_frq)]<-0
set.seed(7)
require(caret)
folds <- createFolds(data_frq$category,k=10)
err.rate.sum = 0
for(i in 1:10){
fold_test <- data_frq[folds[[i]],]   #取folds[[i]]作为测试集
fold_train <- data_frq[-folds[[i]],]   # 剩下的数据作为训练集
# 随机森林
rf_fit = randomForest(category~.,data=fold_train,mtry=4,importance=TRUE,ntree=100)
pred = predict(rf_fit,fold_test)
t = table(pred,fold_test$category)
err.rate.sum <- (sum(t)-sum(diag(t)))/sum(t) + err.rate.sum
print((sum(t)-sum(diag(t)))/sum(t))
pred <- roc(fold_test$category,as.numeric(pred))
plot(pred, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main='随机森林算法ROC曲线')
}
err.rate <- err.rate.sum/10
f(time1)
ntree <- c()
rf_fit = randomForest(category~.,data=data.learn,mtry=1,importance=TRUE,ntree= 100)
rf_fit$importance
pred = predict(rf_fit,data.test)
t = table(pred,data.test$category)
err.rate <- (sum(t)-sum(diag(t)))/sum(t)
ntree <- c(ntree,err.rate)
ntree
ntree <- c()
rf_fit = randomForest(category~.,data=data.learn,mtry=2,importance=TRUE,ntree= 100)
rf_fit$importance
pred = predict(rf_fit,data.test)
t = table(pred,data.test$category)
err.rate <- (sum(t)-sum(diag(t)))/sum(t)
ntree <- c(ntree,err.rate)
rf_fit = randomForest(category~.,data=data.learn,mtry=4,importance=TRUE,ntree= 100)
rf_fit$importance
pred = predict(rf_fit,data.test)
t = table(pred,data.test$category)
err.rate <- (sum(t)-sum(diag(t)))/sum(t)
ntree <- c(ntree,err.rate)
ntree
ntree <- c()
rf_fit = randomForest(category~.,data=data.learn,mtry=1,importance=TRUE,ntree= 100)
rf_fit$importance
pred = predict(rf_fit,data.test)
t = table(pred,data.test$category)
err.rate <- (sum(t)-sum(diag(t)))/sum(t)
ntree <- c(ntree,err.rate)
for (i in 1:30){
rf_fit = randomForest(category~.,data=data.learn,mtry=i,importance=TRUE,ntree= 100)
rf_fit$importance
pred = predict(rf_fit,data.test)
t = table(pred,data.test$category)
err.rate <- (sum(t)-sum(diag(t)))/sum(t)
ntree <- c(ntree,err.rate)
}
ntree <- c()
for (i in 1:30){
rf_fit = randomForest(category~.,data=data.learn,mtry=i,importance=TRUE,ntree= 100)
rf_fit$importance
pred = predict(rf_fit,data.test)
t = table(pred,data.test$category)
err.rate <- (sum(t)-sum(diag(t)))/sum(t)
ntree <- c(ntree,err.rate)
}
ntree
for (i in 1:100){
rf_fit = randomForest(category~.,data=data.learn,mtry=i,importance=TRUE,ntree= 100)
rf_fit$importance
pred = predict(rf_fit,data.test)
t = table(pred,data.test$category)
err.rate <- (sum(t)-sum(diag(t)))/sum(t)
ntree <- c(ntree,err.rate)
}
ntree <- c()
for (i in 1:100){
rf_fit = randomForest(category~.,data=data.learn,mtry=i,importance=TRUE,ntree= 100)
rf_fit$importance
pred = predict(rf_fit,data.test)
t = table(pred,data.test$category)
err.rate <- (sum(t)-sum(diag(t)))/sum(t)
ntree <- c(ntree,err.rate)
}
ntree_num
ntree
ntree <- c()
for (i in 1:20){
rf_fit = randomForest(category~.,data=data.learn,mtry=i,importance=TRUE,ntree= 100)
rf_fit$importance
pred = predict(rf_fit,data.test)
t = table(pred,data.test$category)
err.rate <- (sum(t)-sum(diag(t)))/sum(t)
ntree <- c(ntree,err.rate)
}
ntree_num <- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)
plot(ntree_num,ntree)
ntree_data <- cbind(ntree_num,ntree)
ntree_data <- data.frame(ntree_data)
names(ntree_data) <- c("ntree","err.rate")
ggplot(data=ntree_data, aes(ntree, y=err.rate)) + geom_line(color = "red") +
geom_point(color = "red") +
scale_color_discrete(guide = guide_legend(title = NULL)) + theme_minimal() +
ggtitle("KNN")
names(ntree_data) <- c("mtry","err.rate")
ggplot(data=ntree_data, aes(ntree, y=err.rate)) + geom_line(color = "red") +
geom_point(color = "red") +
scale_color_discrete(guide = guide_legend(title = NULL)) + theme_minimal() +
ggtitle("KNN")
ntree_data <- cbind(ntree_num,ntree)
ntree_data <- data.frame(ntree_data)
names(ntree_data) <- c("mtry","err.rate")
ggplot(data=ntree_data, aes(ntree, y=err.rate)) + geom_line(color = "red") +
geom_point(color = "red") +
scale_color_discrete(guide = guide_legend(title = NULL)) + theme_minimal() +
ggtitle("KNN")
ntree_data
data_frq <- rbind(neg_frq,pos_frq)
ggplot(data=ntree_data, aes(mtry, y=err.rate)) + geom_line(color = "red") +
geom_point(color = "red") +
scale_color_discrete(guide = guide_legend(title = NULL)) + theme_minimal() +
ggtitle("KNN")
ntree <- c()
for (i in 1:100){
rf_fit = randomForest(category~.,data=data.learn,mtry=1,importance=TRUE,ntree= i)
rf_fit$importance
pred = predict(rf_fit,data.test)
t = table(pred,data.test$category)
err.rate <- (sum(t)-sum(diag(t)))/sum(t)
ntree <- c(ntree,err.rate)
}
ntree_num <- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)
plot(ntree_num,ntree)
ntree_data <- cbind(ntree_num,ntree)
ntree_data <- data.frame(ntree_data)
names(ntree_data) <- c("ntree","err.rate")
ggplot(data=ntree_data, aes(ntree, y=err.rate)) + geom_line(color = "red") +
geom_point(color = "red") +
scale_color_discrete(guide = guide_legend(title = NULL)) + theme_minimal() +
ggtitle("KNN")
ntree <- c()
for (i in seq(1,100,2)){
rf_fit = randomForest(category~.,data=data.learn,mtry=1,importance=TRUE,ntree= i)
rf_fit$importance
pred = predict(rf_fit,data.test)
t = table(pred,data.test$category)
err.rate <- (sum(t)-sum(diag(t)))/sum(t)
ntree <- c(ntree,err.rate)
}
ntree_num <- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)
plot(ntree_num,ntree)
ntree_data <- cbind(ntree_num,ntree)
ntree_data <- data.frame(ntree_data)
names(ntree_data) <- c("ntree","err.rate")
ggplot(data=ntree_data, aes(ntree, y=err.rate)) + geom_line(color = "red") +
geom_point(color = "red") +
scale_color_discrete(guide = guide_legend(title = NULL)) + theme_minimal() +
ggtitle("KNN")
ntree <- c()
for (i in seq(1,100,5)){
rf_fit = randomForest(category~.,data=data.learn,mtry=1,importance=TRUE,ntree= i)
rf_fit$importance
pred = predict(rf_fit,data.test)
t = table(pred,data.test$category)
err.rate <- (sum(t)-sum(diag(t)))/sum(t)
ntree <- c(ntree,err.rate)
}
ntree_num <- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)
plot(ntree_num,ntree)
ntree_data <- cbind(ntree_num,ntree)
ntree_data <- data.frame(ntree_data)
names(ntree_data) <- c("ntree","err.rate")
ggplot(data=ntree_data, aes(ntree, y=err.rate)) + geom_line(color = "red") +
geom_point(color = "red") +
scale_color_discrete(guide = guide_legend(title = NULL)) + theme_minimal() +
ggtitle("KNN")
f <- function(start_time) {
start_time <- as.POSIXct(start_time)
dt <- difftime(Sys.time(), start_time, units="secs")
# Since you only want the H:M:S, we can ignore the date...
# but you have to be careful about time-zone issues
format(.POSIXct(dt,tz="GMT"), "%H:%M:%S")
}
time1<-Sys.time()
setwd ( "E:/生物统计/结课论文数据/结课论文数据/Classification" )
# 载入数据
neg_data = readDNAStringSet("ABI5-neg.fasta")
pos_data = readDNAStringSet("ABI5-pos.fasta")
head(neg_data)
head(pos_data)
# 统计ATCG频率
A_neg_frq <- letterFrequency(neg_data,'A')/letterFrequency(neg_data,'AGCT')
T_neg_frq <- letterFrequency(neg_data,'T')/letterFrequency(neg_data,'AGCT')
C_neg_frq <- letterFrequency(neg_data,'C')/letterFrequency(neg_data,'AGCT')
G_neg_frq <- letterFrequency(neg_data,'G')/letterFrequency(neg_data,'AGCT')
A_pos_frq <- letterFrequency(pos_data,'A')/letterFrequency(pos_data,'AGCT')
T_pos_frq <- letterFrequency(pos_data,'T')/letterFrequency(pos_data,'AGCT')
C_pos_frq <- letterFrequency(pos_data,'C')/letterFrequency(pos_data,'AGCT')
G_pos_frq <- letterFrequency(pos_data,'G')/letterFrequency(pos_data,'AGCT')
A_neg_frq <- data.frame(A_neg_frq)
T_neg_frq <- data.frame(T_neg_frq)
C_neg_frq <- data.frame(C_neg_frq)
G_neg_frq <- data.frame(G_neg_frq)
A_pos_frq <- data.frame(A_pos_frq)
T_pos_frq <- data.frame(T_pos_frq)
C_pos_frq <- data.frame(C_pos_frq)
G_pos_frq <- data.frame(G_pos_frq)
neg_frq <- cbind(A_neg_frq,T_neg_frq,C_neg_frq,G_neg_frq)
pos_frq <- cbind(A_pos_frq,T_pos_frq,C_pos_frq,G_pos_frq)
category <- c(rep("neg",nrow(neg_frq)))
neg_frq <- cbind(neg_frq,category)
category <- c(rep("pos",nrow(pos_frq)))
pos_frq <- cbind(pos_frq,category)
head(neg_frq)
head(pos_frq)
data_frq <- rbind(neg_frq,pos_frq)
data_frq[is.na(data_frq)]<-0
set.seed(7)
require(caret)
folds <- createFolds(data_frq$category,k=10)
err.rate.sum = 0
for(i in 1:10){
fold_test <- data_frq[folds[[i]],]   #取folds[[i]]作为测试集
fold_train <- data_frq[-folds[[i]],]   # 剩下的数据作为训练集
# 随机森林
rf_fit = randomForest(category~.,data=fold_train,mtry=1,importance=TRUE,ntree=20)
pred = predict(rf_fit,fold_test)
t = table(pred,fold_test$category)
err.rate.sum <- (sum(t)-sum(diag(t)))/sum(t) + err.rate.sum
print((sum(t)-sum(diag(t)))/sum(t))
pred <- roc(fold_test$category,as.numeric(pred))
plot(pred, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main='随机森林算法ROC曲线')
}
err.rate <- err.rate.sum/10
f(time1)
err.rate
err.rate.sum = 0
for(i in 1:10){
fold_test <- data_frq[folds[[i]],]   #取folds[[i]]作为测试集
fold_train <- data_frq[-folds[[i]],]   # 剩下的数据作为训练集
# 随机森林
model = svm(category~.,data = fold_train, kernel="polynomial")
pred = predict(model,fold_test)
t = table(pred,fold_test$category)
err.rate.sum <- (sum(t)-sum(diag(t)))/sum(t) + err.rate.sum
print((sum(t)-sum(diag(t)))/sum(t))
pred <- roc(fold_test$category,as.numeric(pred))
plot(pred, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main='SVM算法ROC曲线')
}
err.rate <- err.rate.sum/10
f(time1)
err.rate
err.rate.sum = 0
for(i in 1:10){
fold_test <- data_frq[folds[[i]],]   #取folds[[i]]作为测试集
fold_train <- data_frq[-folds[[i]],]   # 剩下的数据作为训练集
# 随机森林
model = svm(category~.,data = fold_train, kernel="sigmoid")
pred = predict(model,fold_test)
t = table(pred,fold_test$category)
err.rate.sum <- (sum(t)-sum(diag(t)))/sum(t) + err.rate.sum
print((sum(t)-sum(diag(t)))/sum(t))
pred <- roc(fold_test$category,as.numeric(pred))
plot(pred, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main='SVM算法ROC曲线')
}
err.rate <- err.rate.sum/10
err.rate
err.rate.sum = 0
for(i in 1:10){
fold_test <- data_frq[folds[[i]],]   #取folds[[i]]作为测试集
fold_train <- data_frq[-folds[[i]],]   # 剩下的数据作为训练集
# 随机森林
model = svm(category~.,data = fold_train, kernel="linera")
pred = predict(model,fold_test)
t = table(pred,fold_test$category)
err.rate.sum <- (sum(t)-sum(diag(t)))/sum(t) + err.rate.sum
print((sum(t)-sum(diag(t)))/sum(t))
pred <- roc(fold_test$category,as.numeric(pred))
plot(pred, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main='SVM算法ROC曲线')
}
err.rate <- err.rate.sum/10
err.rate.sum = 0
for(i in 1:10){
fold_test <- data_frq[folds[[i]],]   #取folds[[i]]作为测试集
fold_train <- data_frq[-folds[[i]],]   # 剩下的数据作为训练集
# 随机森林
model = svm(category~.,data = fold_train, kernel="linear")
pred = predict(model,fold_test)
t = table(pred,fold_test$category)
err.rate.sum <- (sum(t)-sum(diag(t)))/sum(t) + err.rate.sum
print((sum(t)-sum(diag(t)))/sum(t))
pred <- roc(fold_test$category,as.numeric(pred))
plot(pred, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main='SVM算法ROC曲线')
}
err.rate <- err.rate.sum/10
err.rate
err.rate.sum = 0
for(i in 1:10){
fold_test <- data_frq[folds[[i]],]   #取folds[[i]]作为测试集
fold_train <- data_frq[-folds[[i]],]   # 剩下的数据作为训练集
# 随机森林
model = svm(category~.,data = fold_train, kernel="linear")
pred = predict(model,fold_test)
t = table(pred,fold_test$category)
err.rate.sum <- (sum(t)-sum(diag(t)))/sum(t) + err.rate.sum
print((sum(t)-sum(diag(t)))/sum(t))
pred <- roc(fold_test$category,as.numeric(pred))
plot(pred, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main='SVM算法ROC曲线')
}
err.rate <- err.rate.sum/10
err.rate
f <- function(start_time) {
start_time <- as.POSIXct(start_time)
dt <- difftime(Sys.time(), start_time, units="secs")
# Since you only want the H:M:S, we can ignore the date...
# but you have to be careful about time-zone issues
format(.POSIXct(dt,tz="GMT"), "%H:%M:%S")
}
time1<-Sys.time()
setwd ( "E:/生物统计/结课论文数据/结课论文数据/Classification" )
# 载入数据
neg_data = readDNAStringSet("ABI5-neg.fasta")
pos_data = readDNAStringSet("ABI5-pos.fasta")
head(neg_data)
head(pos_data)
# 统计ATCG频率
A_neg_frq <- letterFrequency(neg_data,'A')/letterFrequency(neg_data,'AGCT')
T_neg_frq <- letterFrequency(neg_data,'T')/letterFrequency(neg_data,'AGCT')
C_neg_frq <- letterFrequency(neg_data,'C')/letterFrequency(neg_data,'AGCT')
G_neg_frq <- letterFrequency(neg_data,'G')/letterFrequency(neg_data,'AGCT')
A_pos_frq <- letterFrequency(pos_data,'A')/letterFrequency(pos_data,'AGCT')
T_pos_frq <- letterFrequency(pos_data,'T')/letterFrequency(pos_data,'AGCT')
C_pos_frq <- letterFrequency(pos_data,'C')/letterFrequency(pos_data,'AGCT')
G_pos_frq <- letterFrequency(pos_data,'G')/letterFrequency(pos_data,'AGCT')
A_neg_frq <- data.frame(A_neg_frq)
T_neg_frq <- data.frame(T_neg_frq)
C_neg_frq <- data.frame(C_neg_frq)
G_neg_frq <- data.frame(G_neg_frq)
A_pos_frq <- data.frame(A_pos_frq)
T_pos_frq <- data.frame(T_pos_frq)
C_pos_frq <- data.frame(C_pos_frq)
G_pos_frq <- data.frame(G_pos_frq)
neg_frq <- cbind(A_neg_frq,T_neg_frq,C_neg_frq,G_neg_frq)
pos_frq <- cbind(A_pos_frq,T_pos_frq,C_pos_frq,G_pos_frq)
category <- c(rep("neg",nrow(neg_frq)))
neg_frq <- cbind(neg_frq,category)
category <- c(rep("pos",nrow(pos_frq)))
pos_frq <- cbind(pos_frq,category)
head(neg_frq)
head(pos_frq)
data_frq <- rbind(neg_frq,pos_frq)
data_frq[is.na(data_frq)]<-0
set.seed(7)
require(caret)
folds <- createFolds(data_frq$category,k=10)
err.rate.sum = 0
for(i in 1:10){
fold_test <- data_frq[folds[[i]],]   #取folds[[i]]作为测试集
fold_train <- data_frq[-folds[[i]],]   # 剩下的数据作为训练集
# 随机森林
model = svm(category~.,data = fold_train, kernel="linear")
pred = predict(model,fold_test)
t = table(pred,fold_test$category)
err.rate.sum <- (sum(t)-sum(diag(t)))/sum(t) + err.rate.sum
print((sum(t)-sum(diag(t)))/sum(t))
pred <- roc(fold_test$category,as.numeric(pred))
plot(pred, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main='SVM算法ROC曲线')
}
err.rate <- err.rate.sum/10
f(time1)
set.seed(1234)
rf_fit = randomForest(category~.,data=data.learn,mtry=1,importance=TRUE,ntree= 20)
plot(rf_fit)
set.seed(1234)
rf_fit = randomForest(category~.,data=data.learn,mtry=1,importance=TRUE,ntree= 100)
plot(rf_fit)
set.seed(1234)
rf_fit = randomForest(category~.,data=data.learn,mtry=1,importance=TRUE,ntree= 500)
plot(rf_fit)
set.seed(1234)
rf_fit = randomForest(category~.,data=data.learn,mtry=1,importance=TRUE,ntree= 200)
plot(rf_fit)
set.seed(1234)
rf_fit = randomForest(category~.,data=data.learn,mtry=1,importance=TRUE,ntree= 1000)
plot(rf_fit)
set.seed(1234)
rf_fit = randomForest(category~.,data=data.learn,mtry=1,importance=TRUE,ntree= 400)
plot(rf_fit)
err.rate.sum = 0
for(i in 1:10){
fold_test <- data_frq[folds[[i]],]   #取folds[[i]]作为测试集
fold_train <- data_frq[-folds[[i]],]   # 剩下的数据作为训练集
# 随机森林
rf_fit = randomForest(category~.,data=fold_train,mtry=1,importance=TRUE,ntree=50)
pred = predict(rf_fit,fold_test)
t = table(pred,fold_test$category)
err.rate.sum <- (sum(t)-sum(diag(t)))/sum(t) + err.rate.sum
print((sum(t)-sum(diag(t)))/sum(t))
pred <- roc(fold_test$category,as.numeric(pred))
plot(pred, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main='随机森林算法ROC曲线')
}
err.rate <- err.rate.sum/10
f <- function(start_time) {
start_time <- as.POSIXct(start_time)
dt <- difftime(Sys.time(), start_time, units="secs")
# Since you only want the H:M:S, we can ignore the date...
# but you have to be careful about time-zone issues
format(.POSIXct(dt,tz="GMT"), "%H:%M:%S")
}
time1<-Sys.time()
setwd ( "E:/生物统计/结课论文数据/结课论文数据/Classification" )
# 载入数据
neg_data = readDNAStringSet("ABI5-neg.fasta")
pos_data = readDNAStringSet("ABI5-pos.fasta")
head(neg_data)
head(pos_data)
# 统计ATCG频率
A_neg_frq <- letterFrequency(neg_data,'A')/letterFrequency(neg_data,'AGCT')
T_neg_frq <- letterFrequency(neg_data,'T')/letterFrequency(neg_data,'AGCT')
C_neg_frq <- letterFrequency(neg_data,'C')/letterFrequency(neg_data,'AGCT')
G_neg_frq <- letterFrequency(neg_data,'G')/letterFrequency(neg_data,'AGCT')
A_pos_frq <- letterFrequency(pos_data,'A')/letterFrequency(pos_data,'AGCT')
T_pos_frq <- letterFrequency(pos_data,'T')/letterFrequency(pos_data,'AGCT')
C_pos_frq <- letterFrequency(pos_data,'C')/letterFrequency(pos_data,'AGCT')
G_pos_frq <- letterFrequency(pos_data,'G')/letterFrequency(pos_data,'AGCT')
A_neg_frq <- data.frame(A_neg_frq)
T_neg_frq <- data.frame(T_neg_frq)
C_neg_frq <- data.frame(C_neg_frq)
G_neg_frq <- data.frame(G_neg_frq)
A_pos_frq <- data.frame(A_pos_frq)
T_pos_frq <- data.frame(T_pos_frq)
C_pos_frq <- data.frame(C_pos_frq)
G_pos_frq <- data.frame(G_pos_frq)
neg_frq <- cbind(A_neg_frq,T_neg_frq,C_neg_frq,G_neg_frq)
pos_frq <- cbind(A_pos_frq,T_pos_frq,C_pos_frq,G_pos_frq)
category <- c(rep("neg",nrow(neg_frq)))
neg_frq <- cbind(neg_frq,category)
category <- c(rep("pos",nrow(pos_frq)))
pos_frq <- cbind(pos_frq,category)
head(neg_frq)
head(pos_frq)
data_frq <- rbind(neg_frq,pos_frq)
data_frq[is.na(data_frq)]<-0
set.seed(7)
require(caret)
folds <- createFolds(data_frq$category,k=10)
err.rate.sum = 0
for(i in 1:10){
fold_test <- data_frq[folds[[i]],]   #取folds[[i]]作为测试集
fold_train <- data_frq[-folds[[i]],]   # 剩下的数据作为训练集
# 随机森林
rf_fit = randomForest(category~.,data=fold_train,mtry=1,importance=TRUE,ntree=50)
pred = predict(rf_fit,fold_test)
t = table(pred,fold_test$category)
err.rate.sum <- (sum(t)-sum(diag(t)))/sum(t) + err.rate.sum
print((sum(t)-sum(diag(t)))/sum(t))
pred <- roc(fold_test$category,as.numeric(pred))
plot(pred, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main='随机森林算法ROC曲线')
}
err.rate <- err.rate.sum/10
f(time1)
err.rate.sum = 0
for(i in 1:10){
fold_test <- data_frq[folds[[i]],]   #取folds[[i]]作为测试集
fold_train <- data_frq[-folds[[i]],]   # 剩下的数据作为训练集
# 随机森林
rf_fit = randomForest(category~.,data=fold_train,mtry=1,importance=TRUE,ntree=50)
pred = predict(rf_fit,fold_test)
t = table(pred,fold_test$category)
err.rate.sum <- (sum(t)-sum(diag(t)))/sum(t) + err.rate.sum
print((sum(t)-sum(diag(t)))/sum(t))
pred <- roc(fold_test$category,as.numeric(pred))
plot(pred, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main='随机森林算法ROC曲线')
}
err.rate <- err.rate.sum/10
f(time1)
f <- function(start_time) {
start_time <- as.POSIXct(start_time)
dt <- difftime(Sys.time(), start_time, units="secs")
# Since you only want the H:M:S, we can ignore the date...
# but you have to be careful about time-zone issues
format(.POSIXct(dt,tz="GMT"), "%H:%M:%S")
}
time1<-Sys.time()
err.rate.sum = 0
for(i in 1:10){
fold_test <- data_frq[folds[[i]],]   #取folds[[i]]作为测试集
fold_train <- data_frq[-folds[[i]],]   # 剩下的数据作为训练集
# 随机森林
rf_fit = randomForest(category~.,data=fold_train,mtry=1,importance=TRUE,ntree=50)
pred = predict(rf_fit,fold_test)
t = table(pred,fold_test$category)
err.rate.sum <- (sum(t)-sum(diag(t)))/sum(t) + err.rate.sum
print((sum(t)-sum(diag(t)))/sum(t))
pred <- roc(fold_test$category,as.numeric(pred))
plot(pred, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main='随机森林算法ROC曲线')
}
err.rate <- err.rate.sum/10
f(time1)
err.rate
